import requests
from bs4 import BeautifulSoup
import csv

# Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØµÙØ­ØªÙŠÙ†
urls = [
    'http://books.toscrape.com/catalogue/page-1.html',
    'http://books.toscrape.com/catalogue/page-2.html'
]

books_data = []

for url in urls:
    print(f"ğŸ” ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†: {url}")
    response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})

    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        books = soup.find_all('article', class_='product_pod')

        for book in books:
            # Ø§Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨
            title = book.h3.a['title']

            # Ø§Ù„Ø³Ø¹Ø±
            price = book.find('p', class_='price_color').text

            # Ø±Ø§Ø¨Ø· ØµÙØ­Ø© Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©
            book_link = book.h3.a['href']
            book_page_url = "http://books.toscrape.com/catalogue/" + book_link.replace('../../../', '')

            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø§Øª
            book_response = requests.get(book_page_url, headers={"User-Agent": "Mozilla/5.0"})
            book_soup = BeautifulSoup(book_response.text, 'html.parser')

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø§Øª Ù…Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„
            table = book_soup.find('table', class_='table table-striped')
            num_reviews = table.find_all('tr')[-1].find('td').text  # Ø¢Ø®Ø± ØµÙ Ù‡Ùˆ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø§Øª

            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¨Ø¯ÙˆÙ† Ø§Ù„ØµÙˆØ±Ø©)
            books_data.append([title, price, num_reviews])

    else:
        print(f"âš ï¸ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ {url}")

# Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù…Ù„Ù CSV
with open('books_with_reviews.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(['Title', 'Price', 'Number of Reviews'])
    writer.writerows(books_data)

print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù…Ù„Ù books_with_reviews.csv")
